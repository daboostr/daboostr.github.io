<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>WebLLM</title>
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif; margin: 2rem; }
    textarea { width: 100%; max-width: 900px; }
    button { padding: 0.6rem 1rem; margin-top: 0.5rem; }
    .status { color: #555; margin-left: 0.5rem; min-height: 1.2em; }
    pre { background: #f6f8fa; padding: 1rem; border-radius: 8px; white-space: pre-wrap; word-wrap: break-word; max-width: 900px; }
    .row { margin-bottom: 1rem; display: flex; align-items: center; gap: 0.5rem; flex-wrap: wrap; }
    .small { font-size: 0.9rem; color: #666; }
    .mono { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; }
  </style>
</head>
<body>
  <h1>Run LLM in Your Browser</h1>

  <div class="row small">
    Tip: First load downloads model weights and can take a minute (cached afterwards).
  </div>

  <div class="row small mono" id="env">Detecting environment…</div>

  <div class="row">
    <label for="model">Model:</label>
    <select id="model">
      <option value="Qwen2.5-0.5B-Instruct-q4f32_1-MLC" selected>Qwen2.5-0.5B-Instruct (q4f32_1)</option>
      <option value="Phi-3-mini-4k-instruct-q4f16_1-MLC">Phi-3-mini-4k-instruct (q4f16_1)</option>
    </select>
  </div>

  <div class="row" style="flex-direction: column; align-items: stretch;">
    <textarea id="input" placeholder="Type your prompt here..." rows="6"></textarea>
  </div>

  <div class="row">
    <button id="run">Run LLM</button>
    <span class="status" id="status"></span>
  </div>

  <div class="row" style="flex-direction: column; align-items: stretch;">
    <strong>Output:</strong>
    <pre id="output"></pre>
  </div>

  <script>
    // Environment banner
    function setEnvInfo() {
      const el = document.getElementById('env');
      const env = {
        secure: !!window.isSecureContext,
        coi: !!window.crossOriginIsolated,
        webgpu: 'gpu' in navigator,
      };
      el.textContent = `Env — secure:${env.secure} coi:${env.coi} webgpu:${env.webgpu}`;
    }
    setEnvInfo();

    function loadScript(src, attrs = {}) {
      return new Promise((resolve, reject) => {
        const s = document.createElement('script');
        Object.assign(s, attrs);
        s.src = src;
        s.onload = () => resolve();
        s.onerror = (e) => reject(e);
        document.head.appendChild(s);
      });
    }

    // Load vendored WebLLM from your own domain (no CDN).
    async function loadWebLLM() {
      if (window.webllm) return window.webllm;
      try {
        // Load the vendored UMD bundle
        await loadScript('/assets/webllm/index.min.js');
        // Some bundles expose a different global name — normalize to window.webllm
        window.webllm = window.webllm || window.WebLLM || window.mlc || window.MLC;
      } catch (e) {
        const msg = 'Vendored WebLLM not found at /assets/webllm/index.min.js.';
        console.error(msg, e);
        throw new Error(msg);
      }
      if (!window.webllm) {
        throw new Error('WebLLM script loaded, but no global was found (expected window.webllm or window.WebLLM). If this persists, replace assets/webllm/index.min.js with the UMD from https://unpkg.com/@mlc-ai/web-llm@0.2.79/dist/index.min.js');
      }
      return window.webllm;
    }

    // Attempt engine creation without Web Worker (GitHub Pages isn’t cross-origin isolated)
    async function createEngineNoWorker(webllmObj, modelId, baseOpts) {
      const attempts = [
        { useWebWorker: false },
        { worker: false },
        { use_web_worker: false },
      ];
      let lastErr = null;
      for (const extra of attempts) {
        try {
          return await webllmObj.CreateMLCEngine(modelId, { ...baseOpts, ...extra });
        } catch (e) {
          lastErr = e;
          console.warn('CreateMLCEngine attempt failed with options', extra, e);
        }
      }
      if (lastErr) throw lastErr;
      throw new Error('Failed to create engine (no error detail).');
    }

    // App logic (main-thread only on GitHub Pages)
    function initApp() {
      const inputEl = document.getElementById('input');
      const runBtn = document.getElementById('run');
      const outputEl = document.getElementById('output');
      const statusEl = document.getElementById('status');
      const modelSel = document.getElementById('model');

      let engine = null;
      let currentModel = null;
      let loading = false;

      function setStatus(text) { statusEl.textContent = text || ''; }
      function setRunning(running) {
        runBtn.disabled = running;
        runBtn.textContent = running ? 'Running…' : 'Run LLM';
      }
      function log(...args) { try { console.log('[WebLLM]', ...args); } catch {} }

      function extractText(reply) {
        if (!reply) return '';
        let text = reply?.choices?.[0]?.message?.content;
        if (text) return text;
        text = reply?.output_text || reply?.text || reply?.choices?.[0]?.text;
        if (text) return text;
        try { return JSON.stringify(reply); } catch { return String(reply); }
      }

      async function ensureEngine(modelId) {
        if (engine && currentModel === modelId) return engine;
        if (!window.webllm) {
          throw new Error('Vendored WebLLM library not loaded (window.webllm is undefined).');
        }
        setStatus('Preparing engine…');
        const baseOpts = {
          initProgressCallback: (progress) => {
            const pct = progress?.progress != null ? Math.round(progress.progress * 100) : 0;
            const text = progress?.text || 'Loading';
            setStatus(pct ? `${text} (${pct}%)` : text);
            log('Init progress (main):', progress);
          },
          logLevel: 'info',
        };
        engine = await createEngineNoWorker(window.webllm, modelId, baseOpts);
        currentModel = modelId;
        setStatus('Model ready (main thread).');
        return engine;
      }

      runBtn.addEventListener('click', async () => {
        const prompt = (inputEl.value || '').trim();
        if (!prompt) { inputEl.focus(); return; }
        if (loading) return;
        loading = true;
        setRunning(true);
        outputEl.textContent = '';
        try {
          const modelId = modelSel.value;
          const eng = await ensureEngine(modelId);
          setStatus('Generating…');
          const reply = await eng.chat.completions.create({
            messages: [{ role: 'user', content: prompt }],
            temperature: 0.7,
            max_tokens: 512,
          });
          const text = extractText(reply);
          outputEl.textContent = text || '(No text returned)';
          setStatus('Done.');
        } catch (err) {
          console.error(err);
          outputEl.textContent = '';
          setStatus('Error: ' + (err && err.message ? err.message : String(err)));
        } finally {
          loading = false;
          setRunning(false);
        }
      });

      if (!('gpu' in navigator)) {
        setStatus('WebGPU not detected; please use Chrome/Edge (desktop) version 121+ with WebGPU enabled.');
      }
    }

    // Boot: load vendored library then init app
    (async () => {
      try {
        await loadWebLLM();
        initApp();
      } catch (e) {
        console.error('Failed to load WebLLM:', e);
        const statusEl = document.getElementById('status');
        statusEl.textContent = 'Error loading vendored WebLLM library. See console for details.';
      }
    })();
  </script>
</body>
</html>
